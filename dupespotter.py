#!/usr/bin/env python3

import sys
import os
import re
import re2
import json
import difflib
import subprocess

from hashlib import md5
from urllib.parse import urlsplit, quote, quote_plus, unquote

cache_dir = "cache"


def md5_url(url):
	return md5(url.encode("utf-8")).hexdigest()


def get_cache_filename(url):
	return os.path.join(cache_dir, md5_url(url))


UA = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3452.0 Safari/537.36"

def get_body(url):
	fname = get_cache_filename(url)
	if os.path.exists(fname):
		with open(fname, "rb") as f:
			return f.read()
	else:
		subprocess.call(["wget", "--content-on-error", "-U", UA, url, "-O", fname])
		with open(fname + ".info.json", "w") as f:
			f.write(json.dumps({"url": url}))
		with open(fname, "rb") as f:
			return f.read()


def lower_escapes(url):
	assert isinstance(url, bytes), type(url)
	if b'%' not in url:
		return url
	return re.sub(b'(%[a-fA-F0-9]{2})', lambda m: m.group(1).lower(), url)


def kill_path(path, body):
	body = body.replace(path.encode("utf-8"), b"")
	body = body.replace(path.encode("utf-8").replace(b"/", br"\/"), b"")
	body = body.replace(quote_plus(path).encode("utf-8"), b"")
	body = body.replace(lower_escapes(quote_plus(path).encode("utf-8")), b"")
	path_without_slashes = path.replace("/", "")
	if len(path_without_slashes) >= 5:
		body = body.replace(path_without_slashes.encode("utf-8"), b"")
	# For Dokuwiki
	path_underscored = path.replace("/", "_")
	body             = body.replace(path_underscored.encode("utf-8"), b"")
	# For Drupal "jQuery.extend(Drupal.settings" line
	path_jsoned      = '"' + path.replace("/", "\\u002F") + '"'
	body             = body.replace(path_jsoned.encode("utf-8"), b"")
	if '%' in path:
		unquoted_path = unquote(path)
		if len(unquoted_path) >= 4:
			body = body.replace(quote_plus(unquoted_path).encode("utf-8"), b"")
			body = body.replace(lower_escapes(quote_plus(unquoted_path).encode("utf-8")), b"")
	return body


general_nuke_regexps = [
	# Drupal generates a "theme_token":"..." inside a JSON blob
	# CloudFlare has a petok:"-1413059798-86400"
	r'(petok|_token|applicationTime)"?:("[-_A-Za-z0-9\.]+"|[0-9\.]+)',

	# Handle any 10-256 characters of hex or decimal
	# Minimum of 10 to handle UNIX timestamps
	r'[A-Fa-f0-9\.]{10,256}',

	# Spotted on http://mtnldelhi.in/:
	# id="tabber_container_0_991">
	# id="tab_1-1_340">
	# <a name="tab_1-1_340">
	r'\b(id|name|class)="[^"]{0,100}[-_]\d+"',

	# Randomized anti-spam mailto: lines
	r'<a href="mailto:[^"@]{1,100}@[^"]{2,100}">(&#[0-9a-fA-Fx]{2,4};){3,100}</a>',

	# Kill twitter and facebook share buttons, no matter what kind of
	# URL they stuffed in there.
	r'<div class="fb-like" data-href=".*?</div>',
	r'<a href="https?://twitter.com/share[^"]{0,1000}" class="twitter-share-button.*?</a>',

	# Drupal puts the current URL here, and the casing doesn't always match
	r'<(link rel="(canonical|shortlink|alternate)".{1,1000}?href=|meta property="og:url" content=)"[^"]+" />',

	# Spotted on eff.org drupal
	r'<link href="[^"]+" rel="alternate" hreflang="[^"]+" />',

	# Spotted on http://www.museodelvideojuego.com/ - handles
	# <input type="hidden" name="form_build_id" value="form-ddmhsyCMnpZsHKCQN-l6R1j9EwMT3lHKDI4xXcyFcBA" />
	# Spotted on http://2045.com/
	# <input type="hidden" name="file_uploadToken" value="\d+"
	r'<input type="hidden"[^>]*>',

	# vbulletin
	r'\(\d+ Viewing\)',
	r'Currently Active Users</a>: \d+ \(\d+ members and \d+ guests\)',

	# v= on http://vstreamers.com/v/images/css/p/videos
	# cb= on megahits.sapo.pt
	# pos= on www.smartcast.com.mx
	r'[&\?]((v|cb)=\d+|pos=[A-Za-z0-9=]+)',

	# spotted on espn.go.com and others
	r'(splinks-|var hash = .|":"?)-?\d+',

	# Kill newrelic inline script
	r'window\.NREUM\|\|\(NREUM=\{\}\);NREUM\.info=\{.{1,1000}?.{1,1000}?.{1,1000}?\}',

	# Drupal generates <body class="..."> items based on the URL
	# Generated class="" also spotted on non-Drupal www.minutouno.com
	# Duplicate class="" on stopbadware.org
	r'<(body|div)( id="[^"]+")? class="[^"]+"( class="[^"]+")?( data-src="[^"]{1,1000}[^"]{1,1000}")?',
]

drupal_nuke_regexps = [
	# Kill entire Drupal settings line
	r'jQuery\.extend\(Drupal.settings,.+?}\);',

	# Drupal generates this class id
	r"\bview-dom-id-[0-9a-f]+\b",

	# Drupal sites have randomized sidebar content with these IDs
	r'<div class="views-field views-field-[-a-z]+">.*',

	# sbs.com.au has generated /css_ filenames
	r'/css_[-_A-Za-z0-9]{10,100}\.css',

	# stopbadware.org has some differing autogenerated <style>
	r'<style type="text/css" media="all">@import url\(.{1,1000}?\);</style>',
]

def re2_compile(pattern):
	# Validate with re first for better errors
	re.compile(pattern)
	try:
		return re2.compile(pattern)
	except re.error as e:
		raise RuntimeError(f"re2 failed to compile {repr(pattern)}: {repr(e)}")

def compile_combined_regexp(patterns):
	for pattern in patterns:
		re2_compile(pattern)
	regexp = "|".join("(%s)" % p for p in patterns)
	return re2_compile(regexp)

# fb-re2 doesn't have a .sub, so use the match objects
def null_out_match(arr, match):
	start  = match.start()
	end    = match.end()
	#for i in range(start, end):
	#	arr[i] = 0
	arr[start:end] = b"\x00" * (end - start)

def search_all(regexp, s):
	matches = []
	start = 0
	while True:
		match = regexp.search(s, start)
		if not match:
			break
		start = match.end()
		matches.append(match)
	return matches

def null_out_matches(regexp, s):
	arr = bytearray(s)
	for match in search_all(regexp, s):
		null_out_match(arr, match)
	return bytes(arr)

combined_general_nuke_regexp = compile_combined_regexp(general_nuke_regexps)
combined_drupal_nuke_regexp  = compile_combined_regexp(drupal_nuke_regexps)

def process_body(body, url):
	"""
	Return a post-processed page body that excludes irrelevant content
	that would prevent duplicate pages from being detected as duplicates.
	"""
	assert isinstance(body, bytes), type(body)

	drupal = b"Drupal" in body

	u = urlsplit(url)
	# Needed for www.tragnarion.com
	path = u.path.rstrip('/')
	if path.startswith('/'):
		path = path[1:]
	if len(path) >= 5:
		body = kill_path(path, body)

	# Drupal websites sometimes embed the current URL excluding the
	# first and/or second path component
	shorter_path = '/'.join(path.split('/')[2:])
	if len(shorter_path) >= 50:
		body = kill_path(shorter_path, body)

	if len(u.query) >= 3:
		encoded_query = u.query.encode("utf-8")
		body = body.replace(('?' + u.query).encode("utf-8"), b"")
		body = body.replace(quote('?' + u.query).encode("utf-8"), b"")

	# Strip HTML comments, which sometimes include timestamps or
	# page generation stats
	body = re.sub(br'<\!--.{1,4000}?-->', b"", body, count=1000, flags=re.DOTALL)

	body = null_out_matches(combined_general_nuke_regexp, body)

	if drupal:
		body = null_out_matches(combined_drupal_nuke_regexp, body)

	return body

def compare_bodies(body1, body2, url1, url2):
	# TODO: handle non-utf-8 bodies
	for line in difflib.unified_diff(
		body1.decode("utf-8", "replace").splitlines(keepends=True),
		body2.decode("utf-8", "replace").splitlines(keepends=True),
		fromfile=url1,
		tofile=url2):
		if not "\n" in line:
			line += "\n"
		sys.stdout.buffer.write(line.encode("utf-8"))

def compare_unprocessed_bodies(up_body1, up_body2, url1, url2):
	# Replace NULLs to keep the diffs sane in the tests
	body1 = process_body(up_body1, url1).replace(b"\x00", b"")
	body2 = process_body(up_body2, url2).replace(b"\x00", b"")
	print("{} == md5({!r})".format(md5_url(url1), url1))
	print("{} == md5({!r})".format(md5_url(url2), url2))
	print("After processing,")
	print("len(body({!r})) == {}".format(url1, len(body1)))
	print("len(body({!r})) == {}".format(url2, len(body2)))
	compare_bodies(body1, body2, url1, url2)
	return body1 == body2

def main():
	try:
		os.makedirs(cache_dir)
	except OSError:
		pass

	assert os.path.exists(cache_dir)

	if len(sys.argv) == 2:
		# Just save and print the body
		print(get_body(sys.argv[1]))
	elif len(sys.argv) == 3:
		url1, url2 = sys.argv[1], sys.argv[2]
		compare_unprocessed_bodies(get_body(url1), get_body(url2), url1, url2)
	else:
		assert 0, sys.argv


if __name__ == '__main__':
	main()
